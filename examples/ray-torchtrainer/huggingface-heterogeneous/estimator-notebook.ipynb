{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Fine-tune LLM with PyTorch FSDP and QLora on Amazon SageMaker AI using ModelTrainer\n",
    "\n",
    "In this notebook, we fine-tune LLM on Amazon SageMaker AI, using Python scripts and SageMaker ModelTrainer for executing a training job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca016c-d4fa-4213-a7b3-03b449551449",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907944ea-dbfb-4de0-9e13-1fd28c901031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a287540-f157-4253-9336-db42a67c5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Ray launcher script to the scripts directory. \n",
    "%cp ../../../scripts/launcher.py ./scripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c9e5c-c57c-42cd-baf4-e139422cc147",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "## Setup Configuration file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<aws_profile>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51663-0171-4d54-b16e-f85e3cadb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_id = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "os.environ[\"model_id\"] = model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b95b61-8666-4015-bf2e-fcf68ce38c5b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82089d28-b97a-4956-83fb-d8c46d44fdb5",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "We are going to load [FreedomIntelligence/medical-o1-reasoning-SFT](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc5fa8-51b5-419c-9a87-784022e23e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:55.572481Z",
     "start_time": "2023-11-15T09:24:52.575954Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d973b5e-ac00-4b10-8425-5c4ca4b31f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481791d-9c86-4d32-a39a-918aff5e432f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"FreedomIntelligence/medical-o1-reasoning-SFT\", \"en\", split=\"train[:10000]\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df908a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Number of train elements: \", len(train))\n",
    "print(\"Number of val elements: \", len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368c020-e9a3-48b3-a53b-45404bba9482",
   "metadata": {},
   "source": [
    "Create a prompt template and load the dataset with a random sample to try summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb8edd-35c0-4cf1-82d3-54417bdabd6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:01.435195Z",
     "start_time": "2023-09-03T00:02:01.429794Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def prepare_dataset(sample):\n",
    "\n",
    "    system_text = (\n",
    "        \"You are a deep-thinking AI assistant.\\n\\n\"\n",
    "        \"For every user question, first write your thoughts and reasoning inside <think>...</think> tags, then provide your answer.\"\n",
    "    )\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    messages.append({\"role\": \"system\", \"content\": system_text})\n",
    "    messages.append({\"role\": \"user\", \"content\": sample[\"Question\"]})\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"<think>\\n{sample['Complex_CoT'].lower()}\\n</think>\\n\\n{sample['Response']}\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Apply chat template\n",
    "    sample[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cbedd-7403-467e-8cc6-1d2550d8b8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:10.364459Z",
     "start_time": "2023-09-03T00:02:09.672705Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from random import randint\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"val\": val_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    prepare_dataset, remove_columns=list(train_dataset.features)\n",
    ")\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "val_dataset = dataset[\"val\"].map(\n",
    "    prepare_dataset, remove_columns=list(val_dataset.features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e667af-8197-4d2f-8432-82db6a1d3006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:46:36.592759Z",
     "iopub.status.busy": "2024-12-17T16:46:36.591798Z",
     "iopub.status.idle": "2024-12-17T16:46:36.603128Z",
     "shell.execute_reply": "2024-12-17T16:46:36.598965Z",
     "shell.execute_reply.started": "2024-12-17T16:46:36.592728Z"
    }
   },
   "source": [
    "### Upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f29e5-4aed-4939-8d51-ad3c5268299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db05863-3acb-483b-8e34-2aacbdbc68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302814d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/llm-fine-tuning-modeltrainer-sft-ray\"\n",
    "else:\n",
    "    input_path = f\"datasets/llm-fine-tuning-modeltrainer-sft-ray\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d0321-1bd5-4c62-845a-bb1b9a3891a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "train_dataset.to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "val_dataset.to_json(\"./data/val/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "s3_client.upload_file(\"./data/val/dataset.json\", bucket_name, f\"{input_path}/val/dataset.json\")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(val_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110145d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457beda-117d-4782-9f04-0680c199e98a",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5a09e-97de-4935-82c5-b56445e057fd",
   "metadata": {},
   "source": [
    "We are now ready to fine-tune our model. We will use the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) from transfomers to fine-tune our model. We prepared a script [train.py](./scripts/train.py) which will loads the dataset from disk, prepare the model, tokenizer and start the training.\n",
    "\n",
    "For configuration we use `TrlParser`, that allows us to provide hyperparameters in a `yaml` file. This yaml will be uploaded and provided to Amazon SageMaker similar to our datasets. We are saving the config file as `args.yaml` and upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5aaaf-7d2f-4aae-87af-1b9e6b11b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./args.yaml <<EOF\n",
    "model_id: \"${model_id}\"                           # Hugging Face model id\n",
    "# sagemaker specific parameters\n",
    "output_dir: \"/opt/ml/model\"                       # path to where SageMaker will upload the model \n",
    "checkpoint_dir: \"/opt/ml/checkpoints/\"\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\"   # path to where S3 saves train dataset\n",
    "val_dataset_path: \"/opt/ml/input/data/val/\"       # path to where S3 saves test dataset\n",
    "save_steps: 100                                   # Save checkpoint every this many steps\n",
    "# training parameters\n",
    "lora_r: 32\n",
    "lora_alpha: 64\n",
    "lora_dropout: 0.05                 \n",
    "learning_rate: 1e-4                    # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 4         # batch size per device during training\n",
    "per_device_eval_batch_size: 2          # batch size for evaluation\n",
    "gradient_accumulation_steps: 4         # number of steps before performing a backward/update pass\n",
    "gradient_checkpointing: true           # use gradient checkpointing\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: false                            # use tf32 precision\n",
    "fsdp: \"full_shard auto_wrap offload\"\n",
    "fsdp_config: \n",
    "    backward_prefetch: \"backward_pre\"\n",
    "    cpu_ram_efficient_loading: true\n",
    "    offload_params: true\n",
    "    forward_prefetch: false\n",
    "    use_orig_params: true\n",
    "warmup_steps: 100\n",
    "weight_decay: 0.01\n",
    "merge_weights: true                    # merge weights in the base model\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd27c7-d367-43b1-8b61-ce15e0e262c1",
   "metadata": {},
   "source": [
    "Lets upload the config file to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70937e95-114e-40e1-b26a-49cc1cbd803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "if default_prefix:\n",
    "    input_path = (\n",
    "        f\"s3://{bucket_name}/{default_prefix}/datasets/llm-fine-tuning-modeltrainer-sft-ray\"\n",
    "    )\n",
    "else:\n",
    "    input_path = f\"s3://{bucket_name}/datasets/llm-fine-tuning-modeltrainer-sft-ray\"\n",
    "\n",
    "# upload the model yaml file to s3\n",
    "model_yaml = \"args.yaml\"\n",
    "train_config_s3_path = S3Uploader.upload(\n",
    "    local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\"\n",
    ")\n",
    "\n",
    "os.remove(\"./args.yaml\")\n",
    "\n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329683c-6662-45d3-b864-9cb575f92599",
   "metadata": {},
   "source": [
    "## Fine-tune model\n",
    "\n",
    "Below estimtor will train the model with QLoRA, merge the adapter in the base model and save in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178118a-0f45-4e5f-9bb1-7e5dee146b62",
   "metadata": {},
   "source": [
    "#### Get PyTorch image_uri\n",
    "\n",
    "We are going to use the native PyTorch container image, pre-built for Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5a03c-7660-4729-bf98-67ecb8ffa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.config import load_sagemaker_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaf81c-e8fb-4e42-a90d-50c2c55047bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecfd-e640-4527-99d4-cb3cec9093b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.instance_group import InstanceGroup\n",
    "\n",
    "instance_groups = [\n",
    "    InstanceGroup(\n",
    "        instance_group_name=\"head-instance-group\",\n",
    "        instance_type=\"ml.t3.2xlarge\",\n",
    "        instance_count=1,\n",
    "    ),\n",
    "    InstanceGroup(\n",
    "        instance_group_name=\"worker-instance-group\",\n",
    "        instance_type=\"ml.g5.xlarge\",\n",
    "        instance_count=4,\n",
    "    ),\n",
    "]\n",
    "\n",
    "instance_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7700-7c66-4af8-aea0-da0e5af493bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.6.0\",\n",
    "    instance_type=instance_groups[-1].instance_type,\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabb4d-b0b2-498c-95cb-41ed7d05ee65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:21.382486Z",
     "start_time": "2023-09-03T00:02:20.962208Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f\"train-{model_id.split('/')[-1].replace('.', '-')}-sft-ray\"\n",
    "\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"launcher.py\",\n",
    "    output_path=output_path,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    instance_groups=instance_groups,\n",
    "    max_run=432000,\n",
    "    image_uri=image_uri,\n",
    "    environment={\n",
    "        \"head_instance_group\": \"head-instance-group\",\n",
    "        \"head_num_cpus\": \"0\",\n",
    "        \"head_num_gpus\": \"0\",\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"entrypoint\": \"train_ray.py\",\n",
    "        \"config\": \"/opt/ml/input/data/config/args.yaml\",  # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    enable_remote_debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a386bd9-172c-485c-af45-ebc1d126470b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    s3_data_type=\"S3Prefix\",  # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=train_dataset_s3_path,\n",
    "    distribution=\"FullyReplicated\",  # Available Options: FullyReplicated | ShardedByS3Key\n",
    "    instance_groups=[\"head-instance-group\", \"worker-instance-group\"],\n",
    ")\n",
    "\n",
    "val_input = TrainingInput(\n",
    "    s3_data_type=\"S3Prefix\",  # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=val_dataset_s3_path,\n",
    "    distribution=\"FullyReplicated\",  # Available Options: FullyReplicated | ShardedByS3Key\n",
    "    instance_groups=[\"head-instance-group\", \"worker-instance-group\"],\n",
    ")\n",
    "\n",
    "config_input = TrainingInput(\n",
    "    s3_data_type=\"S3Prefix\",  # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=train_config_s3_path,\n",
    "    distribution=\"FullyReplicated\",  # Available Options: FullyReplicated | ShardedByS3Key\n",
    "    instance_groups=[\"head-instance-group\", \"worker-instance-group\"],\n",
    ")\n",
    "\n",
    "data = {\n",
    "    \"train\": train_input,\n",
    "    \"val\": val_input,\n",
    "    \"config\": config_input,\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e13aa-1df2-43fc-bae4-15f5b7113191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(inputs=data, wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
